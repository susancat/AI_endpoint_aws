{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMpuog6gnJH75cT5ObJ071v"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":6,"metadata":{"id":"s9SaqXVHjj84","executionInfo":{"status":"ok","timestamp":1754968619851,"user_tz":-480,"elapsed":10044,"user":{"displayName":"Irene Zhang","userId":"07788098757015184324"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b2b31778-ef11-4039-9ecd-160c365ebbda"},"outputs":[{"output_type":"stream","name":"stdout","text":["Status: 200\n","Raw body: {\"answer\": \"- Fully managed, on-demand AI inference endpoint that auto-scales with traffic and is billed per invocation, with no server provisioning or maintenance required.\\n- Accepts JSON requests to run a hosted model or pipeline, returning AI results (predictions, completions, embeddings) and includes built-in security (auth), rate limiting, retries, and logging.\"}\n","\n","Pretty JSON:\n","{\n","  \"answer\": \"- Fully managed, on-demand AI inference endpoint that auto-scales with traffic and is billed per invocation, with no server provisioning or maintenance required.\\n- Accepts JSON requests to run a hosted model or pipeline, returning AI results (predictions, completions, embeddings) and includes built-in security (auth), rate limiting, retries, and logging.\"\n","}\n"]}],"source":["import json, requests\n","from google.colab import userdata\n","\n","# Lambda URL & APP_TOKEN from Colab userdata\n","FUNCTION_URL = userdata.get('FUNCTION_URL')\n","APP_TOKEN = userdata.get('APP_TOKEN')\n","\n","# timeout in lambda is 10 sec, 2 sec for lambda to close the call\n","def call_lambda(prompt: str, url=FUNCTION_URL, token=APP_TOKEN, timeout=8):\n","    if not url or not token:\n","        raise ValueError(\"❌ Missing FUNCTION_URL or APP_TOKEN in Colab userdata.\")\n","\n","    headers = {\n","        \"Content-Type\": \"application/json\",\n","        \"x-app-token\": token  # must match Lambda env variable\n","    }\n","    payload = {\"prompt\": prompt}\n","\n","    try:\n","        r = requests.post(url, headers=headers, data=json.dumps(payload), timeout=timeout)\n","        r.raise_for_status()  # raise HTTP Error if not 200\n","        return r\n","    except requests.exceptions.Timeout:\n","        print(\"⚠️ Request to Lambda timed out.\")\n","    except requests.exceptions.RequestException as e:\n","        print(f\"⚠️ Request failed: {e}\")\n","    return None\n","\n","# Test\n","resp = call_lambda(\"Give me 2 bullets describing this serverless AI endpoint.\")\n","if resp:\n","    print(\"Status:\", resp.status_code)\n","    print(\"Raw body:\", resp.text)\n","    try:\n","        print(\"\\nPretty JSON:\")\n","        print(json.dumps(resp.json(), ensure_ascii=False, indent=2))\n","    except Exception:\n","        pass"]}]}